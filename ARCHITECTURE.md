# ArquimedesAI v2.0 Architecture

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ArquimedesAI v2.0                              â”‚
â”‚                  Local RAG System (8-16GB RAM)                       â”‚
â”‚          Semantic Routing + Docling + HNSW-Optimized Qdrant         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Actions   â”‚         â”‚   External Deps   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Add docs       â”‚         â”‚ â€¢ Ollama         â”‚
â”‚   to data/       â”‚         â”‚   (gemma3:4b)    â”‚
â”‚ â€¢ Run CLI        â”‚         â”‚ â€¢ HuggingFace    â”‚
â”‚   -r (routing)   â”‚         â”‚   (BGE-M3)       â”‚
â”‚   -c (convo)     â”‚         â”‚ â€¢ semantic-routerâ”‚
â”‚ â€¢ Discord        â”‚         â”‚   (v2.0)         â”‚
â”‚   mention        â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â”‚                           â”‚
         â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CLI Layer (cli.py)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Commands:                                                           â”‚
â”‚  â€¢ python cli.py index      â†’ Build/update vector index             â”‚
â”‚  â€¢ python cli.py chat -r    â†’ Chat with routing (v2.0)              â”‚
â”‚  â€¢ python cli.py chat -c    â†’ Conversational mode (v2.0)            â”‚
â”‚  â€¢ python cli.py discord    â†’ Start Discord bot                     â”‚
â”‚  â€¢ python cli.py status     â†’ Show system info                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Configuration (settings.py)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Pydantic Settings from .env:                                        â”‚
â”‚  â€¢ ARQ_DATA_DIR, ARQ_STORAGE_DIR                                    â”‚
â”‚  â€¢ ARQ_EMBED_MODEL (BAAI/bge-m3)                                    â”‚
â”‚  â€¢ ARQ_OLLAMA_MODEL (gemma3:latest)                                 â”‚
â”‚  â€¢ ARQ_TOP_K, ARQ_CHUNK_SIZE                                        â”‚
â”‚  â€¢ ARQ_DISCORD_TOKEN                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        INDEXING PIPELINE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

data/
 â”œâ”€â”€ report.pdf
 â”œâ”€â”€ slides.pptx
 â””â”€â”€ notes.md
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ingest/loaders.pyâ”‚  â† Docling + HybridChunker (v1.3)
â”‚ DocumentLoader   â”‚     â€¢ PDF with OCR + table extraction
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â€¢ DOCX, PPTX, XLSX, MD, HTML, images
      â”‚                  â€¢ Structure-aware chunking
      â”‚                  â€¢ Rich metadata (headings, pages, bboxes)
      â”‚ List[Document Chunks]
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ core/embedder.py â”‚  â† HuggingFace + Cache
â”‚ EmbeddingManager â”‚     â€¢ Model: BAAI/bge-m3
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â€¢ Dimension: 1024
      â”‚                  â€¢ Cache: storage/embeddings_cache/
      â”‚ Embeddings
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚core/vector_store.pyâ”‚  â† Qdrant Client (HNSW optimized v1.3.1)
â”‚  QdrantVectorStore â”‚     â€¢ Local: storage/qdrant/
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â€¢ Distance: COSINE
      â”‚                    â€¢ HNSW: m=32, ef_construct=256
      â”‚                    â€¢ on_disk=true (low memory)
      â–¼
  [Persisted]


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                         QUERY PIPELINE (v2.0)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CLI/Discord Query: "O que Ã© uma tag GTM?"
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SEMANTIC ROUTER (v2.0 - Optional)                   â”‚
â”‚                     core/prompt_router.py                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Two-Stage Routing:                                                   â”‚
â”‚  1. Keyword Pre-filter: GTM context detection                         â”‚
â”‚  2. Semantic Classification: BGE-M3 + BM25 (hybrid, alpha=0.3)       â”‚
â”‚                                                                        â”‚
â”‚  Routes (89.5% accuracy):                                             â”‚
â”‚  â”œâ”€ ğŸ“š gtm_qa          â†’ GTM taxonomy questions                       â”‚
â”‚  â”œâ”€ ğŸ› ï¸ gtm_generation  â†’ Tag/trigger/variable creation               â”‚
â”‚  â”œâ”€ âœ… gtm_validation  â†’ Configuration review/audit                   â”‚
â”‚  â””â”€ ğŸ’¬ general_chat    â†’ Fallback for general questions               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ route: RouteType + confidence
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PROMPT SELECTION (v2.0)                              â”‚
â”‚              prompts/{gtm_prompts,base_prompts}.py                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  IF routing enabled:                                                  â”‚
â”‚    â€¢ gtm_qa         â†’ GTM_QA_SYSTEM_PROMPT + style modifier          â”‚
â”‚    â€¢ gtm_generation â†’ GTM_GENERATION_SYSTEM_PROMPT + style           â”‚
â”‚    â€¢ gtm_validation â†’ GTM_VALIDATION_SYSTEM_PROMPT + style           â”‚
â”‚    â€¢ general_chat   â†’ GENERAL_CHAT_SYSTEM_PROMPT + style             â”‚
â”‚  ELSE:                                                                â”‚
â”‚    â€¢ Use base GROUNDED_PROMPT / mode-specific prompt                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ system_prompt: str
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚core/rag_chain.py â”‚  â† LangChain LCEL
â”‚    RAGChain      â”‚     â€¢ Conversational memory (v2.0, optional)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â€¢ Structured citations (v2.0, foundation)
      â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                                           â”‚
      â–¼                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚core/hybrid_retriever â”‚              â”‚ core/llm_local.pyâ”‚
â”‚  HybridRetriever     â”‚              â”‚   LLMManager     â”‚
â”‚                      â”‚              â”‚                  â”‚
â”‚ â€¢ BM25 + Dense (RRF) â”‚              â”‚ â€¢ ChatOllama     â”‚
â”‚ â€¢ Top-K: 8           â”‚              â”‚ â€¢ gemma3:4b      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚ â€¢ Temperature:0.3â”‚
      â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â–¼                                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚ core/reranker.py     â”‚                        â”‚
â”‚  (optional v1.3)     â”‚                        â”‚
â”‚                      â”‚                        â”‚
â”‚ â€¢ Cross-encoder      â”‚                        â”‚
â”‚ â€¢ bge-reranker-v2-m3 â”‚                        â”‚
â”‚ â€¢ Fetch 50 â†’ Top 5   â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
      â”‚                                          â”‚
      â”‚ context: List[Document]                  â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Prompt Template â”‚  â† ChatPromptTemplate
            â”‚  (domain-specificâ”‚     â€¢ System prompt (from router)
            â”‚   or base)       â”‚     â€¢ Context + Query
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â€¢ Answer format
                    â”‚
                    â–¼
            [LLM Generation]
                    â”‚
                    â”‚ response: Dict
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Format Answer   â”‚
            â”‚  + Citations     â”‚
            â”‚  + Route Info    â”‚  â† v2.0: Show route & confidence
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            CLI/Discord Output
            "[Route: ğŸ“š gtm_qa (0.95)]"
            "Uma tag GTM Ã©..."


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                         DATA FLOW SUMMARY (v2.0)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Phase 1: INDEXING (One-time or on-demand)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
data/*.pdf â†’ Docling HybridChunker â†’ BGE-M3 â†’ Qdrant (HNSW optimized)

Phase 2: QUERYING (Real-time)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
v1.x: Query â†’ Hybrid Retrieval â†’ Reranking â†’ Gemma3 â†’ Answer
v2.0: Query â†’ Router (domain detection) â†’ Domain Prompt â†’ Retrieval â†’ Gemma3 â†’ Answer

Phase 3: CONVERSATIONAL (v2.0 - Optional)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Session History â†’ Query â†’ Router â†’ RAG â†’ Response â†’ Update History


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                       COMPONENT DEPENDENCIES (v2.0)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

settings.py (config)
    â†“
    â”œâ†’ core/embedder.py (BGE-M3)
    â”œâ†’ core/llm_local.py (ChatOllama)
    â”œâ†’ core/vector_store.py (Qdrant)
    â”‚      â†‘
    â”‚      â””â”€ core/embedder.py
    â”‚
    â”œâ†’ core/prompt_router.py (v2.0)
    â”‚      â†‘
    â”‚      â””â”€ prompts/gtm_prompts.py (utterances)
    â”‚
    â”œâ†’ ingest/loaders.py (Docling)
    â”‚
    â””â†’ core/rag_chain.py
           â†‘
           â”œâ”€ core/vector_store.py
           â”œâ”€ core/llm_local.py
           â”œâ”€ core/prompt_router.py (v2.0, optional)
           â””â”€ prompts/{gtm_prompts,base_prompts}.py (v2.0)
           
bots/discord_bot.py
    â†“
    â””â†’ core/rag_chain.py

cli.py
    â†“
    â”œâ†’ ingest/* (for index command)
    â”œâ†’ core/rag_chain.py (for chat command)
    â””â†’ bots/* (for discord command)


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                         STORAGE LAYOUT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

storage/
  â”œâ”€â”€ qdrant/                      # Qdrant persistence
  â”‚   â”œâ”€â”€ collection/              
  â”‚   â”‚   â””â”€â”€ arquimedes_chunks/   # Vector collection
  â”‚   â””â”€â”€ meta.json                # Qdrant metadata
  â”‚
  â””â”€â”€ embeddings_cache/            # HuggingFace cache
      â””â”€â”€ BAAI_bge-m3/             # Model-specific cache
          â””â”€â”€ *.pickle             # Cached embeddings


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                      KEY DESIGN DECISIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Separation of Concerns
   â€¢ ingest/   - Document loading and preprocessing
   â€¢ core/     - Embedding, retrieval, generation
   â€¢ bots/     - Interface layer (Discord)

2. Configuration Management
   â€¢ All settings in .env via Pydantic
   â€¢ Type-safe with validation
   â€¢ No hardcoded values

3. Caching Strategy
   â€¢ Embeddings cached at storage/embeddings_cache/
   â€¢ Qdrant persists vectors at storage/qdrant/
   â€¢ No re-computation on restart

4. Async Pattern
   â€¢ Discord bot uses async/await
   â€¢ RAG chain supports both sync/async
   â€¢ Edit-message pattern for UX

5. LangChain LCEL
   â€¢ Composable chains (retriever + document chain)
   â€¢ Future-proof for v1.1 features
   â€¢ Standardized API

6. Local-First
   â€¢ Ollama for LLM (no API calls)
   â€¢ Qdrant local mode (no cloud)
   â€¢ HuggingFace local models
   â€¢ 100% self-hosted

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
